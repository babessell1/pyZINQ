{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bbessell\\Projects\\GitHub\\pyZINQ\n",
      "['.git', '.gitignore', 'License.md', 'py', 'README.md', 'refs', 'tests']\n"
     ]
    }
   ],
   "source": [
    "# set working directory\n",
    "import os\n",
    "os.chdir('..')\n",
    "from py.firth import firth_logistic_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 6)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "   covariate      beta   std_err       fitll       wald         pvals\n",
      "0  intercept  0.120255  0.485542 -138.455068  -0.000000  1.000000e+00\n",
      "1        age -1.105989  0.423662 -138.455068   7.885723  4.982656e-03\n",
      "2         oc -0.068815  0.443794 -138.455068   0.002921  9.568986e-01\n",
      "3        vic  2.268876  0.548417 -138.455068  24.122429  9.040123e-07\n",
      "4       vicl -2.111412  0.543084 -138.455068  20.088726  7.393119e-06\n",
      "5        vis -0.788319  0.417368 -138.455068   3.821936  5.058576e-02\n",
      "6        dia  3.096556  1.675363 -138.455068   9.435747  2.127964e-03\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"refs/uti_data.csv\", delimiter=\";\").drop(columns=[\"Unnamed: 0\"])\n",
    "data.head()\n",
    "\n",
    "covariates = [\"age\", \"oc\", \"vic\", \"vicl\", \"vis\", \"dia\"]\n",
    "X_ = data[covariates].to_numpy().astype(np.float64)\n",
    "y_ = data[\"case\"].to_numpy().astype(np.float64)\n",
    "\n",
    "print(X_.shape)\n",
    "\n",
    "beta, std_err, fitll, wald, pvals = firth_logistic_regression(y_, X_, tol=1e-8, test='lrt')\n",
    "summary = pd.DataFrame({\n",
    "    \"covariate\": [\"intercept\"] + covariates,\n",
    "    \"beta\": beta,\n",
    "    \"std_err\": std_err,\n",
    "    \"fitll\": fitll,\n",
    "    \"wald\": wald,\n",
    "    \"pvals\": pvals\n",
    "})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of R's logistf package:\n",
    "'''\n",
    "logistf(formula = case ~ age + oc + vic + vicl + vis + dia, data = sex2)\n",
    "\n",
    "Model fitted by Penalized ML\n",
    "method\n",
    "                   coef  se(coef) lower 0.95  upper 0.95       Chisq            p\n",
    "(Intercept)  0.12025405 0.4763429 -0.8133609  1.05386904  0.06373235 8.006912e-01      1\n",
    "age         -1.10598131 0.4149021 -1.9191744 -0.29278818  7.10565893 7.684097e-03      1\n",
    "oc          -0.06881673 0.4344026 -0.9202301  0.78259664  0.02509593 8.741283e-01      1\n",
    "vic          2.26887464 0.5384872  1.2134590  3.32429026 17.75293469 2.515292e-05      1\n",
    "vicl        -2.11140817 0.5320395 -3.1541864 -1.06862995 15.74913385 7.232104e-05      1\n",
    "vis         -0.78831694 0.4089620 -1.5898677  0.01323384  3.71565877 5.390435e-02      1\n",
    "dia          3.09601166 1.5052197  0.1458353  6.04618801  4.23063350 3.970062e-02\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff betas:  [ 1.07547291e-06 -7.31802781e-06  1.28657029e-06  1.49313811e-06\n",
      " -3.60615652e-06 -1.72431510e-06  5.44770210e-04]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m correct_pvals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8.006912e-01\u001b[39m, \u001b[38;5;241m7.684097e-03\u001b[39m, \u001b[38;5;241m8.741283e-01\u001b[39m, \u001b[38;5;241m2.515292e-05\u001b[39m, \u001b[38;5;241m7.232104e-05\u001b[39m, \u001b[38;5;241m5.390435e-02\u001b[39m, \u001b[38;5;241m3.970062e-02\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff betas: \u001b[39m\u001b[38;5;124m\"\u001b[39m, beta \u001b[38;5;241m-\u001b[39m correct_betas)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff pvals: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpvals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcorrect_pvals\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(beta, correct_betas, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(pvals, correct_pvals, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "correct_betas = [0.12025405, -1.10598131, -0.06881673, 2.26887464, -2.11140817, -0.78831694, 3.09601166]\n",
    "correct_pvals = [8.006912e-01, 7.684097e-03, 8.741283e-01, 2.515292e-05, 7.232104e-05, 5.390435e-02, 3.970062e-02]\n",
    "\n",
    "print(\"diff betas: \", beta - correct_betas)\n",
    "print(\"diff pvals: \", pvals - correct_pvals)\n",
    "\n",
    "assert np.allclose(beta, correct_betas, atol=1e-3)\n",
    "assert np.allclose(pvals, correct_pvals, atol=5e-2)\n",
    "print(\"pass\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.722841800001333\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "print(timeit.timeit(lambda: firth_logistic_regression(y_, X_, test='wald'), number=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(23/100)*15000/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP WIP WIP WIP\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy import special, linalg\n",
    "import warnings\n",
    "\n",
    "@njit\n",
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "@njit\n",
    "def logistic(x, eps=1e-5):\n",
    "    \"\"\" Compute logistic function, clipping the output to be within (eps, 1-eps). \"\"\"\n",
    "    # Add clipping to avoid values exactly at 0 or 1\n",
    "    return np.clip(1 / (1 + np.exp(-x)), eps, 1 - eps)\n",
    "\n",
    "@njit\n",
    "def compute_log_likelihood(beta, X, y):\n",
    "    logits = X @ beta\n",
    "    log_likelihood = np.sum(y * logits - np.log(1 + np.exp(logits)))\n",
    "    return log_likelihood\n",
    "\n",
    "@njit\n",
    "def firth_penalty(log_likelihood, H):\n",
    "    sign, logdet = np.linalg.slogdet(-H)\n",
    "    return -(log_likelihood + 0.5 * logdet)\n",
    "\n",
    "@njit\n",
    "def compute_fisher_information(X, pi, eps=np.finfo(float).eps):\n",
    "    \"\"\" Compute Fisher information matrix, ensuring numerical stability. \"\"\"\n",
    "    # Use an epsilon value to ensure pi * (1 - pi) does not result in zero rows\n",
    "    W = np.diag(np.clip(pi * (1 - pi), eps, None))  # Add a small epsilon\n",
    "    H = X.T @ (W @ X)\n",
    "    return np.linalg.pinv(H)\n",
    "\n",
    "@njit\n",
    "def compute_score(X, y, pi, H):\n",
    "    root_diag_h = np.sqrt(np.diag(X @ (np.linalg.pinv(-H) @ X.T)))\n",
    "    delta_pi = root_diag_h * (0.5 - pi)\n",
    "    U = X.T @ (y - pi + delta_pi)\n",
    "    return U\n",
    "\n",
    "@njit\n",
    "def compute_standard_errors(inverse_fisher_info):\n",
    "    return np.sqrt(np.diag(inverse_fisher_info))\n",
    "\n",
    "@njit\n",
    "def compute_wald_test(beta, standard_errors):\n",
    "    wald_stats = np.square(beta / standard_errors)\n",
    "    p_values = 2 * (1 - norm.cdf(np.abs(beta / standard_errors)))  # two-tailed\n",
    "\n",
    "    return wald_stats, p_values\n",
    "\n",
    "@njit\n",
    "def compute_likelihood_ratio_test(full_ll, reduced_ll):\n",
    "    lr_stat = -2 * (reduced_ll - full_ll)\n",
    "    p_value = chi2.sf(lr_stat, df=1)  # df=1 for a single parameter test\n",
    "    return lr_stat, p_value\n",
    "\n",
    "\n",
    "def firth_logistic_regression(y, X, max_iter=1000, tol=1e-6, test='wald'):\n",
    "    N, p = X.shape\n",
    "    beta = np.zeros(p+1)\n",
    "    X = np.hstack((np.ones((N, 1)), X))  # Adding a column for the intercept\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        pi = logistic(X @ beta)\n",
    "        H = compute_fisher_information(X, pi)\n",
    "        ll = compute_log_likelihood(beta, X, y)\n",
    "\n",
    "        if firth_penalty(ll, H) < tol:\n",
    "            break\n",
    "\n",
    "        U = compute_score(X, y, pi, H)\n",
    "\n",
    "        inverse_H = linalg.pinv(-H)  # Inverting the Hessian matrix\n",
    "        print(\"Shape of inverse_H:\", inverse_H.shape)\n",
    "        print(\"Shape of U:\", U.shape)\n",
    "        delta_beta = inverse_H @ U\n",
    "        print(\"Shape of delta_beta:\", delta_beta.shape)\n",
    "        beta = beta + delta_beta\n",
    "\n",
    "        if np.max(np.abs(delta_beta)) < tol:\n",
    "            break\n",
    "    \n",
    "    se = None\n",
    "\n",
    "    if test == 'null_model':\n",
    "        return None, None, ll, None, None\n",
    "    elif test == 'wald':\n",
    "        se = compute_standard_errors(np.linalg.pinv(-H))\n",
    "        stats, pvals = compute_wald_test(beta, se)\n",
    "    elif test == 'lrt':\n",
    "        null_X = np.delete(X, i, axis=1)\n",
    "        _, _, null_ll = firth_logistic_regression(y, null_X, test='null_model')\n",
    "        stats, pvals = compute_likelihood_ratio_test(ll, null_ll)\n",
    "    else:\n",
    "        raise ValueError('Invalid test type')\n",
    "\n",
    "    se = compute_standard_errors(np.linalg.pinv(-H)) if se is None else se\n",
    "    \n",
    "    return beta, se, ll, stats, pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../refs/uti_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../refs/uti_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m      4\u001b[0m covariates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvicl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdia\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bbessell\\Miniconda3\\envs\\bioinf593\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bbessell\\Miniconda3\\envs\\bioinf593\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\bbessell\\Miniconda3\\envs\\bioinf593\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bbessell\\Miniconda3\\envs\\bioinf593\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\bbessell\\Miniconda3\\envs\\bioinf593\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../refs/uti_data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../refs/uti_data.csv\", delimiter=\";\").drop(columns=[\"Unnamed: 0\"])\n",
    "data.head()\n",
    "\n",
    "covariates = [\"age\", \"oc\", \"vic\", \"vicl\", \"vis\", \"dia\"]\n",
    "X_ = data[covariates].to_numpy().astype(np.float64)\n",
    "y_ = data[\"case\"].to_numpy().astype(np.float64)\n",
    "\n",
    "beta, std_err, fitll, wald, pvals = firth_logistic_regression(y_, X_, tol=1e-8, test='wald')\n",
    "summary = pd.DataFrame({\n",
    "    \"covariate\": [\"intercept\"] + covariates,\n",
    "    \"beta\": beta,\n",
    "    \"std_err\": std_err,\n",
    "    \"fitll\": fitll,\n",
    "    \"wald\": wald,\n",
    "    \"pvals\": pvals\n",
    "})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model fitted by Penalized ML\n",
    "method\n",
    "                   coef  se(coef) lower 0.95  upper 0.95       Chisq            p\n",
    "(Intercept)  0.12025405 0.4763429 -0.8133609  1.05386904  0.06373235 8.006912e-01      1\n",
    "age         -1.10598131 0.4149021 -1.9191744 -0.29278818  7.10565893 7.684097e-03      1\n",
    "oc          -0.06881673 0.4344026 -0.9202301  0.78259664  0.02509593 8.741283e-01      1\n",
    "vic          2.26887464 0.5384872  1.2134590  3.32429026 17.75293469 2.515292e-05      1\n",
    "vicl        -2.11140817 0.5320395 -3.1541864 -1.06862995 15.74913385 7.232104e-05      1\n",
    "vis         -0.78831694 0.4089620 -1.5898677  0.01323384  3.71565877 5.390435e-02      1\n",
    "dia          3.09601166 1.5052197  0.1458353  6.04618801  4.23063350 3.970062e-02\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A working but slow implementation of Firth logistic regression\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "from numba import jit, njit\n",
    "from scipy.stats import chi2, norm\n",
    "\n",
    "\n",
    "@njit\n",
    "def firth_likelihood(loglike_val, H):\n",
    "    return -(loglike_val + .5*np.log(np.linalg.det(-H)))\n",
    "\n",
    "\n",
    "@njit\n",
    "def fit_firth_numba(betas, hessian, y, X):\n",
    "    pi = 1 / (  1 + np.exp( -(X @ betas) )  )\n",
    "    W = np.diag(pi * (1 - pi))\n",
    "    cov = np.linalg.pinv(-hessian)\n",
    "\n",
    "    # build hat matrix\n",
    "    rootW = np.sqrt(W)\n",
    "    H = X.T @ rootW.T\n",
    "    H = cov @ H\n",
    "    H = (rootW @ X) @ H\n",
    "\n",
    "    # penalised score\n",
    "                        # h_i\n",
    "    U = X.T @ (y - pi + np.diag(H) * (.5 - pi))\n",
    "    new_betas = betas + cov @ U\n",
    "        \n",
    "    return new_betas\n",
    "\n",
    "\n",
    "def firth_logistic_regression(y : np.array,\n",
    "                              X : np.ndarray,\n",
    "                              max_iter : int = 1000,\n",
    "                              tol : float = 1e-6,\n",
    "                              test : str = 'lrt',\n",
    "                              ) -> tuple[np.array, np.array, float]:\n",
    "    \"\"\"\n",
    "    Perform Firth logistic regression.\n",
    "\n",
    "    beta_hat = argmin | sum(y_i  - pi_i + h_i(1/2 - pi_i))x_{ir} |\n",
    "        i -> N, r -> p = len(beta)\n",
    "\n",
    "    Where: \n",
    "        h_i = ith diagonal element of:\n",
    "            W^(1/2)X(X'WX)^(-1)X'W^(1/2)\n",
    "\n",
    "        |I(beta)|^(1/2) = (X'WX)^(1/2) = Fisher information matrix\n",
    "\n",
    "        pi_i = 1 / (1 + exp(-x_i*beta)) = probability of success\n",
    "        W = diag(pi_i(1-pi_i)) = weight matrix\n",
    "        X = design matrix (n x p) \n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)\n",
    "    logit_model = sm.Logit(y, X)\n",
    "\n",
    "    # fit null model\n",
    "    null_model = sm.Logit(y, np.ones((len(y), 1)))\n",
    "    null_result = null_model.fit(disp=0)\n",
    "    start_vec = np.zeros(X.shape[1])\n",
    "    start_vec[0] = null_result.params[0]\n",
    "    betas = start_vec\n",
    "\n",
    "    H = logit_model.hessian(betas)\n",
    "    ll = logit_model.loglike(betas)\n",
    "\n",
    "    conv = False\n",
    "    for i in range(max_iter):\n",
    "        new_betas = fit_firth_numba(betas, H, y, X)\n",
    "        ll_next = logit_model.loglike(betas)\n",
    "        H_next = logit_model.hessian(betas)\n",
    "\n",
    "        while firth_likelihood(ll_next, H_next) < firth_likelihood(ll, H):\n",
    "            new_betas = betas + 0.5 * (new_betas - betas)\n",
    "            ll, H = ll_next, H_next\n",
    "            ll_next = logit_model.loglike(new_betas)\n",
    "            H_next = logit_model.hessian(new_betas)\n",
    "            conv = (np.linalg.norm(new_betas - betas) < tol)\n",
    "            if conv: break\n",
    "        \n",
    "        betas = new_betas\n",
    "        if conv: break\n",
    "\n",
    "    if new_betas is None:\n",
    "        sys.stderr.write('Firth regression failed\\n')\n",
    "        return None\n",
    "\n",
    "    # Calculate stats\n",
    "    fitll = ll_next\n",
    "\n",
    "    # add small value to the hessian to ensure it is invertible\n",
    "    H_next += np.eye(H_next.shape[0]) * 1e-6\n",
    "    bse = np.sqrt(np.diag(np.linalg.pinv(-H_next)))\n",
    "\n",
    "    if test == 'null_model':\n",
    "        return None, None, fitll, None, None\n",
    "    \n",
    "    elif test == 'wald':\n",
    "        # Wald test for each coefficient\n",
    "        stats = abs(betas / bse)\n",
    "        pvals = 2 * ( 1 - norm.cdf(stats) )\n",
    "\n",
    "    elif test == 'lrt':\n",
    "        stats, pvals = [], [] # store chi2 stats and pvals\n",
    "        # Likelihood ratio test\n",
    "        for i, bse in enumerate(bse):\n",
    "            null_X = np.delete(X, i, axis=1)\n",
    "\n",
    "            _, _, null_fitll, _, _ = \\\n",
    "                firth_logistic_regression(\n",
    "                    y, null_X, max_iter, tol, test='null_model')\n",
    "            \n",
    "            lr = -2 * (null_fitll - fitll)\n",
    "            stats.append(lr)     \n",
    "            lr_pval = 1 if lr < 0 else chi2.sf(lr, 1)\n",
    "            pvals.append(lr_pval)\n",
    "\n",
    "\n",
    "    return betas, bse, fitll, stats, pvals\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinf593",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
